# **Prometheus**

### Prometheus architecture

Prometheus is a time series DB. It can monitor your&#x20;

1. Processes (node, go, rust…)

1) Hosts

   1. ![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F4deeef9d-9a71-4d44-a13e-5f5f20323d98%2FScreenshot_2024-05-26_at_6.37.41_PM.png?table=block\&id=38205709-ee79-4fb3-ba38-9436b3810565\&cache=v2 "notion image")

 

<https://prometheus.io/docs/introduction/overview/>

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F1ff6e5b6-d82f-47be-ba52-04dedd73a71d%2FScreenshot_2024-05-26_at_12.34.44_PM.png?table=block\&id=cdf71ade-bca7-44dc-8c7b-a14324f84971\&cache=v2 "notion image")

 

#### 1. Multi-dimensional data model with time series data identified by metric name and key/value pairs

Prometheus stores its data in a time series format where each data point consists of:

* **Metric Name:** A name that identifies the type of data, e.g., `http_requests_total`.

- **Labels (Key/Value Pairs):** Additional metadata that further identifies and differentiates the time series, e.g., `method="GET"` and `handler="/api"`. Labels provide a way to add dimensions to the metric data, allowing for flexible and detailed querying and analysis.

 

#### 2. PromQL, a flexible query language to leverage this dimensionality

PromQL lets you query on top of all your timeseries data.

For example

```
sum(http_requests_total{job="api-server", status="500"})
```

would give you all the http requests that your server handled with status code 500

#### 3. No reliance on distributed storage; single server nodes are autonomous

Prometheus is designed to be a standalone, single-node system that does not require external distributed storage solutions. Each Prometheus server node is autonomous, meaning it can independently scrape, store, and query time series data. This design simplifies the system architecture and operational overhead but also means that Prometheus is not inherently horizontally scalable. However sharding techniques can be used to manage larger deployments.

#### 4. Time series collection happens via a pull model over HTTP

Prometheus primarily uses a **pull model** to collect metrics:

* **Pull Model:** Prometheus periodically scrapes metrics from configured targets by making HTTP requests to the `/metrics` endpoint exposed by the targets. This approach allows Prometheus to control the scraping intervals and retry logic.

- Targets expose their metrics in a specific format that Prometheus understands, typically using client libraries provided by Prometheus for various languages and environments.

#### 5. Pushing time series is supported via an intermediary gateway

While Prometheus generally uses a pull model, it also supports a **push model** through the **Pushgateway**:

* **Pushgateway:** An intermediary service that allows applications and batch jobs to push metrics to it. The Pushgateway then exposes these metrics for Prometheus to scrape. This is useful for short-lived jobs or services that cannot be scraped reliably.

#### 6. Targets are discovered via service discovery or static configuration

Prometheus supports multiple methods for discovering targets to scrape:

* **Service Discovery:** Dynamically discovers targets using various service discovery mechanisms like Kubernetes, Consul, AWS, etc. This allows Prometheus to automatically update its target list as the environment changes.

- **Static Configuration:** Manually specifies the list of targets in the configuration file. This is straightforward but less flexible compared to service discovery.

#### 7. Multiple modes of graphing and dashboarding support

Prometheus offers several ways to visualize and interact with the collected metrics:

* **Prometheus UI:** A built-in web interface for ad-hoc queries and simple graphing.

- **Grafana:** A popular open-source dashboarding tool that integrates well with Prometheus, providing rich visualization and dashboarding capabilities.

* **Alertmanager:** A component of the Prometheus ecosystem used to handle alerts generated by Prometheus queries, allowing for complex alerting rules and notification integrations.

# Adding raw metrics

#### Lets build an express app that exports metrics

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F5bafa676-ae1f-438a-8837-258f198e178e%2FScreenshot_2024-05-26_at_6.39.29_PM.png?table=block\&id=05820985-c7c7-4f27-b398-31a958ea582d\&cache=v2 "notion image")

 

Let’s add some `hand made` metrics to an express app

* Initialize a TS project

```
npm init -y
npx tsc --init
```

* Replace rootDir and outDir

```
"rootDir": "./src",
"outDir": "./dist",
```

* Add dependencies

```
npm install express @types/express
```

* Create `src/index.ts`

```
import express from "express";

const app = express();

app.use(express.json());

app.get("/user", (req, res) => {
    res.send({
        name: "John Doe",
        age: 25,
    });
});

app.post("/user", (req, res) => {
    const user = req.body;
    res.send({
        ...user,
        id: 1,
    });
});

app.listen(3000);
```

* Create a middleware that tracks the total time to handle a request (`middleware.ts`)

```
import { NextFunction, Request, Response } from "express";

export const middleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    next();
    const endTime = Date.now();
    console.log(`Request took ${endTime - startTime}ms`);
}
```

* Add the middleware globally

```
app.use(middleware);
```

* Update package.json to add scripts

```
"scripts": {
    "build": "tsc -b",
    "start": "npm run build && node dist/index.js"
},
```

* Run the application

```
npm run start
```

* Try to send a request and notice the logs

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F0665cc8d-824f-48a0-9a6d-b58d884dc44a%2FScreenshot_2024-05-26_at_12.58.00_PM.png?table=block\&id=9911d44c-f9b5-443b-bae6-b021f9a1c841\&cache=v2 "notion image")



# Add prometheus

Lets try putting this data inside prometheus next.

### Types of metrics in Prometheus

#### Counter

* A counter is a cumulative metric that only increases.

- Example: Counting the number of HTTP requests.

#### Gauge

* A gauge is a metric that can go up and down. It can be used to measure values that fluctuate, such as the current number of active users or the current memory usage.

- Example: Measuring the current memory usage

#### Histogram

* A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.

- Example: Measuring the duration of HTTP requests.



# Counters

Let’s add logic to count the number of requests (throughput) of our application.

 

* Install prom-client

```
npm install prom-client
```

* Create a new `metrics/requestCount.ts` file

```
import { NextFunction, Request, Response } from "express";
import client from "prom-client";

// Create a counter metric
const requestCounter = new client.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
});

export const requestCountMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();

    res.on('finish', () => {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);

        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
    });

    next();
};
```

* Add the middleware to `src/index.ts`

- Add a `/metrics` endpoint to `src/index.ts`

```
import client from "prom-client";

app.get("/metrics", async (req, res) => {
    const metrics = await client.register.metrics();
    res.set('Content-Type', client.register.contentType);
    res.end(metrics);
})
```

* Start the app

```
npm run start
```

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F135f80dd-4c79-4206-8e55-822fee5e9ba7%2FScreenshot_2024-05-26_at_1.44.36_PM.png?table=block\&id=faf5ff90-05e2-4095-ba51-f61693e7f817\&cache=v2 "notion image")



# Better structure

Before we proceed, lets aggregate all the metric creation and cleanup logic in the same file.

 

* Create a new middleware called `metrics/index.ts`&#x20;

```
import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();

    res.on('finish', function() {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);
    
        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
    });
    next();
}

```

* Update the `metrics/requestCount.ts` to export the `requestCounter` and remove the cleanup logic from here

```
import { NextFunction, Request, Response } from "express";
import client from "prom-client";

// Create a counter metric
export const requestCounter = new client.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
});

```

* Update `src/index.ts` to use the `metricsMiddleware`&#x20;

```
import { metricsMiddleware } from "./metrics";
app.use(metricsMiddleware);
```



# Gauge

Lets add a gauge metric to our app

* Create `metrics/activeRequests.ts` , export a `Gauge` from it

```
import client from "prom-client";

export const activeRequestsGauge = new client.Gauge({
    name: 'active_requests',
    help: 'Number of active requests'
});
```

* Import it and update `metrics/index.ts`

```
import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";
import { activeRequestsGauge } from "./activeRequests";

export const cleanupMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    activeRequestsGauge.inc();

    res.on('finish', function() {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);
        
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
        activeRequestsGauge.dec();
    });
}

```

* Add an artificial delay to the get endpoint

```
app.get("/user", async (req, res) => {
    await new Promise((resolve) => setTimeout(resolve, 1000));
    res.send({
        name: "John Doe",
        age: 25,
    });
});
```

* Hit the `/user` endpoint a few times

- Check the metrics

 

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Ff5267128-f329-4bd8-b673-3907e41f9cab%2FScreenshot_2024-05-26_at_1.51.32_PM.png?table=block\&id=cdf6d1e7-87d1-4d06-b7f3-bb2daf935c38\&cache=v2 "notion image")



# Histograms

Histograms let you store data in various buckets in a `cumulative` fashion

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F39db1b5d-efc6-4d2f-8dcb-42cdaccd19ae%2FScreenshot_2024-05-26_at_6.44.09_PM.png?table=block\&id=ef761049-7b31-4193-ae88-76bd58a5782a\&cache=v2 "notion image")

* Add `metrics/requestCount.ts`&#x20;

```
import client from "prom-client";

export const httpRequestDurationMicroseconds = new client.Histogram({
    name: 'http_request_duration_ms',
    help: 'Duration of HTTP requests in ms',
    labelNames: ['method', 'route', 'code'],
    buckets: [0.1, 5, 15, 50, 100, 300, 500, 1000, 3000, 5000] // Define your own buckets here
});
```

💡

Buckets here represent the `key points` you want to measure in your app. How many people had request handled in 0.1ms, 5ms, 15ms … This is because prometheus is not a DB, it just exposes all the metrics on an endpoint. That endpoint cant server all the data, and hence prometheus doesnt store the exact values, but how many requests were less than 0.1, 5, 15 …

 

* Update `metrics/index.ts`

```
import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";
import { activeRequestsGauge } from "./activeRequests";
import { httpRequestDurationMicroseconds } from "./requestTime";

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    activeRequestsGauge.inc();

    res.on('finish', function() {
        const endTime = Date.now();
        const duration = endTime - startTime;
    
        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });

        httpRequestDurationMicroseconds.observe({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            code: res.statusCode
        }, duration);

        activeRequestsGauge.dec();
    });
    next();
}
```

* Go to the metrics endpoint

 

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F9e255e2d-1231-4383-b30f-8752dffb8e2c%2FScreenshot_2024-05-26_at_2.35.31_PM.png?table=block\&id=6d931234-49cd-4e72-98c0-2b454fee0cd4\&cache=v2 "notion image")

 

It says

1. There were 0 to `/user` requests that were handled in less than 0.1ms

1) There were 0 to `/user` requests that were handled in less than 5ms

1. There were 0 to `/user` requests that were handled in less than 15ms

1) There were 0 to `/user` requests that were handled in less than 50ms

1. There were 0 to `/user` requests that were handled in less than 100ms

1) There were 0 to `/user` requests that were handled in less than 500ms

1. There were 0 to `/user` requests that were handled in less than 1000ms

1) There were 1 to `/user` requests that were handled in less than 3000ms

1. There were 1 to `/user` requests that were handled in less than 5000ms

 

As you can see, this is cumulative.

Number of requests being handled in less than 5000ms = Number of requests being handled in less than 3000ms + Number of requests that took between 3000-5000ms



# Final code

<https://github.com/100xdevs-cohort-2/week-26-prom>

 

With this code, you can run an application and see a bunch of metrics on it in a slightly ugly fashion on an endpoint

You can also try this on your side here - <https://prom.100xdevs.com/metrics>

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F10d7c846-6c5b-4c01-acf1-f91f10ba9651%2FScreenshot_2024-05-26_at_3.04.44_PM.png?table=block\&id=ad6944b1-367b-4cf7-adc8-6e84c10e315f\&cache=v2 "notion image")



# Actually starting prometheus

 

Let’s start an actual prometheus process that scrapes the linux machine

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F2af80c12-6f38-4a1f-8459-85b33e6debf6%2FScreenshot_2024-05-26_at_6.45.37_PM.png?table=block\&id=91070bd4-de67-4310-8751-3e74c0fb6b33\&cache=v2 "notion image")

 

Until now, we’ve exposed a `/metrics` endpoint but no one is `scraping` using it.

Prometheus actually scrapes (pulls) these metrics so you can visualise them over time (time series data)

For that, you need to start prometheus and give it the `source` of the metrics

 

* Add `prometheus.yml`

```
global:
  scrape_interval: 15s # How frequently to scrape targets

scrape_configs:
  - job_name: 'nodejs-app'
    static_configs:
      - targets: ['localhost:3000']
```

* Start prometheus locally

```
docker run -p 9090:9090 -v ./prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus
```

💡

You can start it w/o docker as well by installing it from source

* Try visiting [localhost:9090](http://localhost:9090/) , you will notice a problem in the `status/targets` section

  * ![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fc32994cb-87a6-46eb-9994-de2a78618c2a%2FScreenshot_2024-05-26_at_3.23.54_PM.png?table=block\&id=baa3ff1a-d2bf-4423-88a6-ce43030bb894\&cache=v2 "notion image")

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F09da6f6a-10ab-4f0a-965a-40ba6ada9ea4%2FScreenshot_2024-05-26_at_3.23.40_PM.png?table=block\&id=f3699376-d5d7-4065-a8c9-82861e74179c\&cache=v2 "notion image")

💡

The problem is that nothing is running on port 3000 on the prom container, and hence it cant discover our service

 

### Containerising the app

* Create a Dockerfile for the Node app

```
FROM node:20

# Create app directory
WORKDIR /usr/src/app

# Install app dependencies
COPY package*.json ./

RUN npm install

# Bundle app source
COPY . .

EXPOSE 3000
CMD [ "node", "app.js" ]
```

* Create a docker-compose that starts the nodejs app as well as the prom container

```
version: '3.8'

services:
  node-app:
    build: ./
    ports:
      - "3000:3000"
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./:/etc/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring

networks:
  monitoring:

```

* Update prometheus.yml

```
global:
  scrape_interval: 15s # How frequently to scrape targets

scrape_configs:
  - job_name: 'nodejs-app'
    static_configs:
      - targets: ['node-app:3000']
```

* Start docker compose

```
docker-compose up
```

* Try going to <http://localhost:9090/>

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fdb7739b1-6e96-4c13-95ba-1ee4723f75cf%2FScreenshot_2024-05-26_at_3.36.12_PM.png?table=block\&id=22daf3f9-12b1-4409-bcb9-b08e8a5127e1\&cache=v2 "notion image")

* Try executing a query

```
http_requests_total
```

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F991f89c0-a044-408c-b227-5cb62f04c82a%2FScreenshot_2024-05-26_at_3.37.19_PM.png?table=block\&id=79a1b46c-75bd-4178-9e7e-3534cc94d0fa\&cache=v2 "notion image")



# Queries in Prom

## Simple queries (counters and gauges)

Here are some Prometheus queries you can run on `localhost:9090` to analyze the metrics provided:

#### 1. Total Number of HTTP Requests

To get the total number of HTTP requests per route

```
http_requests_total
```

#### 2. Total Number of HTTP Requests (cumulative)

```
sum(http_requests_total)
```

#### 3. HTTP Request Duration

```
http_request_duration_ms_sum
```

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F03d4e4fb-5ee9-4d8e-a50b-94bfe30616ad%2FScreenshot_2024-05-26_at_3.41.49_PM.png?table=block\&id=eeb4ba6f-a0ac-47ec-bbd5-da4d1865d903\&cache=v2 "notion image")

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fe4561673-8e38-4662-825e-41aac0848009%2FScreenshot_2024-05-26_at_3.41.57_PM.png?table=block\&id=dfa43545-1b4a-493b-af76-2b7d3ea14e43\&cache=v2 "notion image")

#### 4. Count of total number of http requests

```
http_request_duration_ms_count
```

#### 5. Average time it took to handle all requests

```
http_request_duration_ms_sum / http_request_duration_ms_count
```

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fb8227cd5-328b-409a-a1ac-07d30e36c2ec%2FScreenshot_2024-05-26_at_3.42.56_PM.png?table=block\&id=985bbfdf-78da-4074-9b12-56f85b44807d\&cache=v2 "notion image")

## Complex queries (histograms)

#### 1. See the request duration in buckets

```
http_request_duration_ms_bucket
```

#### 2. See requests for a specific route

```
http_request_duration_ms_bucket{method="GET", route="/metrics", code="200"}
```

 

# Graphs in prom

Prometheus also lets you visualise data as graphs

Lets see a few queries

 

#### 1. Total number of requests

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fff289af1-94d5-480b-b7ad-ca5f627c1978%2FScreenshot_2024-05-26_at_4.09.41_PM.png?table=block\&id=a6bb2580-38f3-4def-a370-cd981106d737\&cache=v2 "notion image")

💡

As you can tell, this is a very vague metric since it is cumulative. It is the total number of requests, but you usually want to see the `rate` at which requests are coming.

 

#### 2. Rate of number of requests

 

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fe3abafe1-162b-4cf7-af13-6f55262b3986%2FScreenshot_2024-05-26_at_4.11.03_PM.png?table=block\&id=8c6c326a-e00d-4073-bfe4-9b00f1f6a132\&cache=v2 "notion image")

#### 3. Rate of all the requests (sum up /metrics and /user requests)

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F623da3fb-747f-476c-8eaf-66b442d81e6e%2FScreenshot_2024-05-26_at_4.11.47_PM.png?table=block\&id=223a017a-9a73-4c0a-88f3-17636b23abbe\&cache=v2 "notion image")

 

#### 4. Average HTTP request duration with timeseries (5 minute buckets)

```
rate(http_request_duration_ms_sum[5m]) / rate(http_request_duration_ms_count[5m])
```

 

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F9e639a98-bbf9-48fc-b250-e89146df9c28%2FScreenshot_2024-05-26_at_4.14.50_PM.png?table=block\&id=75845e32-0706-477a-a4d0-e21e503f5d19\&cache=v2 "notion image")



# Grafana

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fffb2e08d-1473-46e0-8a26-06ebdc42314a%2FScreenshot_2024-05-26_at_4.01.02_PM.png?table=block\&id=2ed3b1ad-2a0a-4fd9-a691-797b84f46684\&cache=v2 "notion image")

Ref - <https://grafana.com/>

Even though you can use the prom interface, grafanna makes your life much easier

You can connect your prometheus data to grafana to be able to visualise your data better

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F163483aa-3214-46ce-9755-1cd40dabdd10%2FScreenshot_2024-05-26_at_6.48.19_PM.png?table=block\&id=30fa1d3f-d76d-48a1-a892-86c99c83d546\&cache=v2 "notion image")



# Installing grafana in docker compose

* Update docker-compose

```
version: '3.8'

services:
  node-app:
    build: ./
    ports:
      - "3000:3000"
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./:/etc/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    networks:
      - monitoring
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

networks:
  monitoring:
```

 

Try visiting `localhost:3001`

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F122a0c18-b1f5-4018-a8c6-585192f171bb%2FScreenshot_2024-05-26_at_4.18.56_PM.png?table=block\&id=8a1e9c65-33fd-466e-bfbe-f461e5f9a8af\&cache=v2 "notion image")



# Adding prometheus as a source

 

* Create a connection

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F676ba9f1-45f3-4545-8b61-1033fe2c2978%2FScreenshot_2024-05-26_at_4.22.13_PM.png?table=block\&id=42d27185-1481-47e6-8166-13104bce82e4\&cache=v2 "notion image")

* Source URL

```
http://prometheus:9090
```

### Assignment

Try building a dashboard that has

1. Total number of requests to `/metrics` endpoint

1) Number of http requests to the `/metrics` endpoint per second

1. Total number of requests to the `/user` endpoint

1) Number of http request  to the `/user` endpoint per second

1. A gauge that lets you see the current active requests

 

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fb4649a9c-45a3-421f-9088-d38945f1c3e9%2FScreenshot_2024-05-26_at_5.38.00_PM.png?table=block\&id=75513fe0-0f42-468b-9dc7-a9abf88dd109\&cache=v2 "notion image")



# Alerting

 

Grafana provides you with a way to set alerts on metrics.

![notion image](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2F700313bf-59ac-4f8d-b5ec-fdd0574cb6e5%2FScreenshot_2024-05-26_at_5.56.09_PM.png?table=block\&id=a44624d7-2e0c-465b-8fbc-46e331222fcc\&cache=v2 "notion image")

### Steps

1. Enter a name for it - High number of requests

1) Define query

```
rate(http_requests_total{route="/user"}[$__rate_interval])
```

1. Setup alert threshold (lets say 50 requests/s)

1) Set evaluation behaviour

   1. How often should we check this alert?
   2. Create  folder so that it can be re-used later

1. Add labels

   1. Team: Backend
   2. Type: Error

1) Save

 

#### Testing

Send a lot of requests to the `/user` endpoint and ensure it triggers the alert

 

#### Notifying

1. Create a new contact point&#x20;

1) Connect the alert to the contact point in `Notification policies`

This will not send a real email unless you’ve put in SMTP credentials while starting the apps
